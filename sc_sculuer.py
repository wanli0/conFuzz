#!/usr/bin/env python3
import os
import sys
import mmap
import time
import math
import random
import argparse
import subprocess
import concurrent.futures
import threading
from datetime import datetime
from pathlib import Path
from collections import defaultdict

# ====================== å‘½ä»¤è¡Œå‚æ•°é…ç½® ======================
def parse_args():
    parser = argparse.ArgumentParser(
        description="SA-Driven Fuzzer Resource Scheduler",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument("-n", "--num-instances", type=int, required=True,
                        help="å¹¶è¡Œå®ä¾‹æ•°é‡")
    parser.add_argument("-f", "--fuzzer", type=str, required=True,
                        help="æ¨¡ç³Šæµ‹è¯•å·¥å…·åç§° (e.g. pfuzz)")
    parser.add_argument("-p", "--project", type=str, required=True,
                        help="æµ‹è¯•ç›®æ ‡é¡¹ç›® (e.g. openssl)")
    parser.add_argument("-t", "--test-scenario", type=str, required=True,
                        help="æµ‹è¯•åœºæ™¯åç§° (e.g. handshake_test)")
    parser.add_argument("-c", "--config-pool", nargs='+', required=True,
                        help="å¯ç”¨æµ‹è¯•æ¨¡æ¿åˆ—è¡¨")
    parser.add_argument("-s", "--start-idx", type=int, default=1,
                        help="å®ä¾‹èµ·å§‹ç¼–å·")
    parser.add_argument("-i", "--interval", type=int, default=60,
                        help="è°ƒåº¦å†³ç­–é—´éš”ï¼ˆç§’ï¼‰")
    parser.add_argument("--init-temp", type=float, default=1000.0,
                        help="åˆå§‹æ¸©åº¦")
    parser.add_argument("--cool-rate", type=float, default=0.95,
                        help="é™æ¸©é€Ÿç‡")
    parser.add_argument("--min-temp", type=float, default=1.0,
                        help="æœ€ä½æ¸©åº¦")
    parser.add_argument("--max-stagnant", type=int, default=20,
                        help="æœ€å¤§åœæ»è¿­ä»£æ¬¡æ•°")
    
    return parser.parse_args()

# ====================== å¢å¼ºå‹è¦†ç›–ç‡ç›‘æ§ ======================
class AsyncCoverageMonitor(CoverageMonitor):
    def __init__(self, instance_manager):
        super().__init__(instance_manager)
        self.refresh_lock = threading.Lock()
        self.worker = threading.Thread(target=self._async_refresh, daemon=True)
        self.worker.start()

    def _async_refresh(self):
        """å¼‚æ­¥åˆ·æ–°çº¿ç¨‹"""
        while True:
            with self.refresh_lock:
                active_instances = [
                    i for i, inst in self.instance_manager.instances.items()
                    if inst['active']
                ]
                
                # åˆ†æ‰¹æ¬¡å¤„ç†é¿å…åŒæ—¶æ‰“å¼€è¿‡å¤šæ–‡ä»¶
                batch_size = 16
                for i in range(0, len(active_instances), batch_size):
                    batch = active_instances[i:i+batch_size]
                    self._process_batch(batch)
            
            time.sleep(5)  # é™ä½åˆ·æ–°é¢‘ç‡

    def _process_batch(self, inst_ids):
        """æ‰¹é‡å¤„ç†å®ä¾‹åˆ·æ–°"""
        for inst_id in inst_ids:
            inst = self.instance_manager.instances[inst_id]
            edge_path = inst['shm_paths']['cov_edge']
            
            try:
                mtime = os.path.getmtime(edge_path)
                if mtime > self.last_update.get(inst_id, 0):
                    with open(edge_path, "r+b") as f:
                        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
                            data = bytes(mm)
                            if data:
                                self.edge_coverage[inst_id] = data
                                self.last_update[inst_id] = mtime
            except Exception as e:
                print(f"[WARN] å®ä¾‹ {inst_id} æ•°æ®åˆ·æ–°å¤±è´¥: {str(e)}")

    def get_merged_coverage(self, active_instances):
        """ä¼˜åŒ–åçš„ä½è¿ç®—åˆå¹¶"""
        if not active_instances:
            return 0

        # ä½¿ç”¨numpyåŠ é€Ÿè¿ç®—ï¼ˆéœ€å®‰è£…numpyï¼‰
        try:
            import numpy as np
            max_len = max(len(self.edge_coverage[i]) for i in active_instances)
            merged = np.zeros(max_len, dtype=np.uint8)
            
            for inst_id in active_instances:
                data = self.edge_coverage.get(inst_id, b'')
                np_data = np.frombuffer(data, dtype=np.uint8, count=min(len(data), max_len))
                merged[:len(np_data)] |= np_data
            
            return np.unpackbits(merged).sum()
        except ImportError:
            # å›é€€åˆ°åŸç”ŸPythonå®ç°
            return super().get_merged_coverage(active_instances)

class CoverageMonitor:
    def __init__(self, instance_manager):
        self.instance_manager = instance_manager
        self.edge_coverage = defaultdict(bytes)
        self.last_update = defaultdict(float)

    def _safe_read_shm(self, path):
        try:
            with open(path, "r+b") as f:
                with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
                    return bytes(mm)
        except Exception as e:
            print(f"[WARN] æ— æ³•è¯»å– {path}: {str(e)}")
            return b''

    def refresh(self):
        for inst_id, inst in self.instance_manager.instances.items():
            if not inst['active']:
                continue
            
            edge_path = inst['shm_paths']['cov_edge']
            try:
                mtime = os.path.getmtime(edge_path)
                if mtime > self.last_update.get(inst_id, 0):
                    data = self._safe_read_shm(edge_path)
                    if data:
                        self.edge_coverage[inst_id] = data
                        self.last_update[inst_id] = mtime
            except Exception as e:
                print(f"[ERROR] åˆ·æ–°å®ä¾‹ {inst_id} æ•°æ®å¤±è´¥: {str(e)}")

    @staticmethod
    def count_branches(data):
        return sum(bin(byte).count('1') for byte in data)

    def get_instance_coverage(self, inst_id):
        return self.count_branches(self.edge_coverage.get(inst_id, b''))

    def get_merged_coverage(self, active_instances):
        active_data = [self.edge_coverage[i] for i in active_instances]
        if not active_data:
            return 0

        merged = bytearray(active_data[0])
        for data in active_data[1:]:
            if len(data) > len(merged):
                merged.extend(b'\x00' * (len(data) - len(merged)))
            for i in range(len(data)):
                merged[i] |= data[i]
        return self.count_branches(merged)

# ====================== èµ„æºæ± ç®¡ç†å™¨ ======================

class OptimizedResourcePool(ResourcePool):
    def _init_pool(self):
        """å¹¶è¡Œåˆå§‹åŒ–å…±äº«å†…å­˜"""
        self.instances = {}
        self.shm_paths = {}

        # ç”Ÿæˆæ‰€æœ‰å®ä¾‹é…ç½®
        instance_configs = [
            (i, {
                'cov_edge': f"/dev/shm/{self.args.project}_edge_{i}",
                'cov_bitmap': f"/dev/shm/{self.args.project}_bitmap_{i}"
            })
            for i in range(self.args.start_idx, 
                          self.args.start_idx + self.args.num_instances)
        ]

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œåˆ›å»ºå…±äº«å†…å­˜
        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            futures = [
                executor.submit(self._create_shm_parallel, paths) 
                for _, paths in instance_configs
            ]
            concurrent.futures.wait(futures)

        # åˆå§‹åŒ–å®ä¾‹
        for inst_id, paths in instance_configs:
            self.instances[inst_id] = {
                'id': inst_id,
                'active': False,
                'process': None,
                'current_config': None,
                'shm_paths': paths,
                'weight': 1.0
            }
            self.shm_paths[inst_id] = paths

    def _create_shm_parallel(self, paths):
        """å¹¶è¡Œåˆ›å»ºå…±äº«å†…å­˜çš„è¾…åŠ©æ–¹æ³•"""
        for path in paths.values():
            if not Path(path).exists():
                try:
                    subprocess.run(
                        f"dd if=/dev/zero of={path} bs=10M count=1 status=none",
                        shell=True, check=True
                    )
                    os.chmod(path, 0o666)
                except subprocess.CalledProcessError as e:
                    print(f"[ERROR] åˆ›å»º {path} å¤±è´¥: {str(e)}")

class ResourcePool:
    def __init__(self, args):
        self.args = args
        self.instances = {}
        self.shm_paths = {}
        self._init_pool()

    def _init_pool(self):
        """åˆå§‹åŒ–èµ„æºæ± ï¼Œæ¯ä¸ªå®ä¾‹åˆ†é…å›ºå®šå…±äº«å†…å­˜"""
        for i in range(self.args.start_idx, 
                      self.args.start_idx + self.args.num_instances):
            shm_paths = {
                'cov_edge': f"/dev/shm/{self.args.project}_edge_{i}",
                'cov_bitmap': f"/dev/shm/{self.args.project}_bitmap_{i}"
            }
            
            # åˆ›å»ºå…±äº«å†…å­˜æ–‡ä»¶ï¼ˆæ•´ä¸ªç”Ÿå‘½å‘¨æœŸåªåˆ›å»ºä¸€æ¬¡ï¼‰
            self._create_shm(shm_paths)
            
            self.instances[i] = {
                'id': i,
                'active': False,
                'process': None,
                'current_config': None,
                'shm_paths': shm_paths,
                'weight': 1.0
            }
            self.shm_paths[i] = shm_paths

    def _create_shm(self, paths):
        """åˆ›å»ºå…±äº«å†…å­˜æ–‡ä»¶ï¼ˆä»…åœ¨åˆå§‹åŒ–æ—¶æ‰§è¡Œï¼‰"""
        for path in paths.values():
            if not Path(path).exists():
                subprocess.run(
                    f"dd if=/dev/zero of={path} bs=10M count=1 status=none",
                    shell=True, check=True
                )
                os.chmod(path, 0o666)

    def switch_config(self, inst_id, new_config):
        """åˆ‡æ¢å®ä¾‹é…ç½®"""
        inst = self.instances[inst_id]
        
        # åœæ­¢å½“å‰æµ‹è¯•
        if inst['process']:
            inst['process'].terminate()
            try:
                inst['process'].wait(timeout=5)
            except:
                pass
        
        # å¯åŠ¨æ–°é…ç½®
        env = os.environ.copy()
        env.update({
            "LUCKY_GLOBAL_MMAP_FILE": inst['shm_paths']['cov_edge'],
            "SHM_ENV_VAR": inst['shm_paths']['cov_bitmap'],
            "FUZZER_INSTANCE_ID": str(inst_id)
        })
        
        try:
            proc = subprocess.Popen(
                ["timeout", "86400", "mono",
                 "/root/PFuzz/output/linux_x86_64_release/bin/peach.exe",
                 new_config],
                env=env,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.STDOUT
            )
            inst.update({
                'process': proc,
                'active': True,
                'current_config': new_config,
                'weight': self._calc_weight(new_config)
            })
            print(f"[+] å®ä¾‹ {inst_id} åˆ‡æ¢è‡³é…ç½®: {Path(new_config).name}")
        except Exception as e:
            print(f"[ERROR] å®ä¾‹ {inst_id} é…ç½®åˆ‡æ¢å¤±è´¥: {str(e)}")
            inst['active'] = False

    def _calc_weight(self, config_path):
        """åŠ¨æ€è®¡ç®—é…ç½®æƒé‡"""
        name = Path(config_path).stem.lower()
        if 'heavy' in name: return 2.0
        if 'medium' in name: return 1.5
        return 1.0

    def activate(self, inst_id, config):
        """æ¿€æ´»å®ä¾‹"""
        if not self.instances[inst_id]['active']:
            self.switch_config(inst_id, config)

    def deactivate(self, inst_id):
        """æš‚åœå®ä¾‹ï¼ˆä¿ç•™å…±äº«å†…å­˜ï¼‰"""
        inst = self.instances[inst_id]
        if inst['process']:
            inst['process'].terminate()
            try:
                inst['process'].wait(timeout=5)
            except:
                pass
        inst.update({'active': False, 'process': None})
        print(f"[.] å®ä¾‹ {inst_id} å·²æš‚åœ")

    def cleanup(self):
        """æœ€ç»ˆæ¸…ç†æ‰€æœ‰å…±äº«å†…å­˜"""
        for paths in self.shm_paths.values():
            for path in paths.values():
                try:
                    os.remove(path)
                    print(f"æ¸…ç†å…±äº«å†…å­˜: {path}")
                except:
                    pass

# ====================== å¼ºåŒ–æ¨¡æ‹Ÿé€€ç«æ ¸å¿ƒ ======================
class HighPerformanceSAScheduler(EnhancedSAScheduler):
    def _generate_candidate(self, current_set):
        """é’ˆå¯¹å¤§è§„æ¨¡å®ä¾‹ä¼˜åŒ–çš„å€™é€‰è§£ç”Ÿæˆ"""
        # æ‰¹é‡æ“ä½œï¼šæ¯æ¬¡è°ƒæ•´5%çš„å®ä¾‹ï¼ˆè‡³å°‘1ä¸ªï¼‰
        num_changes = max(1, int(len(current_set)*0.05))
        
        # é€‰æ‹©ç­–ç•¥
        if random.random() < 0.8:  # 80%æ¦‚ç‡åŸºäºæ•ˆç‡
            return self._batch_optimize(current_set, num_changes)
        else:  # 20%æ¦‚ç‡éšæœºæ¢ç´¢
            return self._batch_random(current_set, num_changes)

    def _batch_optimize(self, current_set, num_changes):
        """æ‰¹é‡ä¼˜åŒ–ä½æ•ˆå®ä¾‹"""
        efficiencies = []
        for inst_id in current_set:
            cov = self.monitor.get_instance_coverage(inst_id)
            weight = self.pool.instances[inst_id]['weight']
            efficiencies.append( (inst_id, cov/(weight+1e-6)) )
        
        efficiencies.sort(key=lambda x: x[1])
        
        # æ›¿æ¢æ•ˆç‡æœ€ä½çš„Nä¸ªå®ä¾‹
        for _ in range(num_changes):
            if not efficiencies:
                break
            
            worst_id = efficiencies.pop(0)[0]
            new_config = random.choice([
                c for c in self.args.config_pool 
                if c != self.pool.instances[worst_id]['current_config']
            ])
            self.pool.switch_config(worst_id, new_config)
        
        return current_set

    def _batch_random(self, current_set, num_changes):
        """æ‰¹é‡éšæœºè°ƒæ•´"""
        candidates = random.sample(list(current_set), num_changes)
        for inst_id in candidates:
            new_config = random.choice(self.args.config_pool)
            self.pool.switch_config(inst_id, new_config)
        return current_set
class EnhancedSAScheduler:
    def __init__(self, pool, monitor, args):
        self.pool = pool
        self.monitor = monitor
        self.args = args
        self.temp = args.init_temp
        self.best_state = set()
        self.best_energy = float('inf')  # åˆå§‹åŒ– best_energy
        self.stagnation = 0
        
        # åˆå§‹åŒ–æ‰€æœ‰å®ä¾‹
        for inst_id in self.pool.instances:
            cfg = random.choice(args.config_pool)
            self.pool.switch_config(inst_id, cfg)

    def _calculate_energy(self, active_set):
        """åŠ¨æ€èƒ½é‡è®¡ç®—"""
        resource_cost = sum(
            self.pool.instances[i]['weight'] for i in active_set
        )
        coverage = self.monitor.get_merged_coverage(active_set)
        return (0.7 * resource_cost) - (0.3 * coverage)

    def _generate_candidate(self, current_set):
        """ç”Ÿæˆå€™é€‰æ–¹æ¡ˆï¼šåŠ¨æ€é…ç½®åˆ‡æ¢"""
        new_set = current_set.copy()
        
        # é€‰æ‹©æ“ä½œç±»å‹
        if random.random() < 0.7:  # 70%æ¦‚ç‡åˆ‡æ¢ä½æ•ˆå®ä¾‹
            return self._optimize_by_efficiency(new_set)
        else:  # 30%æ¦‚ç‡éšæœºæ¢ç´¢
            return self._random_exploration(new_set)

    def _optimize_by_efficiency(self, current_set):
        """åŸºäºæ•ˆç‡ä¼˜åŒ–"""
        efficiencies = []
        for inst_id in current_set:
            cov = self.monitor.get_instance_coverage(inst_id)
            weight = self.pool.instances[inst_id]['weight']
            efficiencies.append( (inst_id, cov/(weight+1e-6)) )
        
        if efficiencies:
            # æ›¿æ¢æ•ˆç‡æœ€ä½çš„å®ä¾‹
            efficiencies.sort(key=lambda x: x[1])
            worst_id = efficiencies[0][0]
            new_config = random.choice([
                c for c in self.args.config_pool 
                if c != self.pool.instances[worst_id]['current_config']
            ])
            self.pool.switch_config(worst_id, new_config)
            current_set.remove(worst_id)
            current_set.add(worst_id)  # ä¿æŒé›†åˆä¸å˜ï¼Œå®é™…å·²åˆ‡æ¢é…ç½®
        return current_set

    def _random_exploration(self, current_set):
        """éšæœºæ¢ç´¢æ–°é…ç½®"""
        inst_id = random.choice(list(current_set))
        new_config = random.choice(self.args.config_pool)
        self.pool.switch_config(inst_id, new_config)
        return current_set  # é›†åˆä¸å˜ï¼Œä»…å†…éƒ¨é…ç½®å˜åŒ–

    def step(self):
        current_active = set(i for i, inst in self.pool.instances.items() 
                            if inst['active'])
        candidate = self._generate_candidate(current_active)
        
        current_e = self._calculate_energy(current_active)
        candidate_e = self._calculate_energy(candidate)
        
        accept_prob = math.exp(-(candidate_e - current_e)/self.temp) \
            if candidate_e > current_e else 1.0
        
        if random.random() < accept_prob:
            # åº”ç”¨æ–°çŠ¶æ€ï¼ˆå®é™…å·²åœ¨_generate_candidateä¸­åˆ‡æ¢ï¼‰
            if candidate_e < self.best_energy:
                self.best_energy = candidate_e
                self.best_state = candidate
                self.stagnation = 0
            else:
                self.stagnation += 1

        # é™æ¸©
        self.temp = max(self.temp * self.args.cool_rate, self.args.min_temp)

# ====================== ä¸»ç¨‹åºæ‰§è¡Œæµç¨‹ ======================
def main():
    args = parse_args()
    
    # è‡ªåŠ¨è°ƒæ•´å‚æ•°
    if args.num_instances >= 32:
        args.interval = max(args.interval, 120)  # é™ä½è°ƒåº¦é¢‘ç‡
        args.max_stagnant = min(args.max_stagnant, 10)  # æ›´å¿«é‡ç½®
        
    pool = OptimizedResourcePool(args)
    monitor = AsyncCoverageMonitor(pool)
    scheduler = HighPerformanceSAScheduler(pool, monitor, args)
    pool = None
    
    try:
        print("\n" + "="*40)
        print(" åŠ¨æ€èµ„æºæ± è°ƒåº¦ç³»ç»Ÿ ".center(40, '='))
        print(f" å®ä¾‹æ•°é‡: {args.num_instances}")
        print(f" å¯ç”¨é…ç½®: {', '.join([Path(p).name for p in args.config_pool])}")
        
        pool = ResourcePool(args)
        monitor = CoverageMonitor(pool)
        scheduler = EnhancedSAScheduler(pool, monitor, args)
        
        iteration = 0
        while True:
            iteration += 1
            print(f"\n--- è¿­ä»£ {iteration} [æ¸©åº¦: {scheduler.temp:.2f}] ---")
            
            start_time = time.time()
            monitor.refresh()
            scheduler.step()
            
            # è·å–å½“å‰çŠ¶æ€
            active_set = [i for i, inst in pool.instances.items() if inst['active']]
            merged_cov = monitor.get_merged_coverage(active_set)
            
            print(f"æ€»åˆ†æ”¯è¦†ç›–: {merged_cov}")
            print("å®ä¾‹çŠ¶æ€:")
            for inst_id in active_set:
                inst = pool.instances[inst_id]
                print(f"  â–ª å®ä¾‹{inst_id}: {Path(inst['current_config']).name} | " +
                      f"æƒé‡: {inst['weight']:.1f} | " +
                      f"è¦†ç›–: {monitor.get_instance_coverage(inst_id)}")
            
            if scheduler.stagnation >= args.max_stagnant:
                print(f"\nâš ï¸ è¿ç»­{args.max_stagnant}æ¬¡æœªæ”¹è¿›ï¼Œé‡ç½®æ¸©åº¦")
                scheduler.temp = args.init_temp
                scheduler.stagnation = 0
            
            time.sleep(args.interval)
    
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­...")
    except Exception as e:
        print(f"\n[CRITICAL] å‘ç”Ÿé”™è¯¯: {str(e)}")
    finally:
        if pool:
            print("\n" + "="*40)
            print(" æ¸…ç†èµ„æº ".center(40, '='))
            pool.cleanup()
        print("="*40 + "\n")

if __name__ == "__main__":
    main()
